{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMhZAYRD0gbHsaOJGB4hxxp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaltyWriter38/Int2Group22/blob/main/BatchNorm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a3TMtvy4ZrBq"
      },
      "outputs": [],
      "source": [
        "import torch  \n",
        "import torch.nn as nn \n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim \n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyper parameters \n",
        "Epoch_num = 100\n",
        "batch_size =64\n",
        "learning_rate = 0.01\n",
        "\n",
        "width = 224\n",
        "height = 224\n",
        "\n",
        "device =  torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwEjMZitZr12",
        "outputId": "5e60da19-ca86-4e08-8cf0-3388e4bfa26f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_transfrom = transforms.Compose([transforms.Resize((width,height)), transforms.RandomRotation(30),\n",
        "                transforms.RandomVerticalFlip(),transforms.RandomHorizontalFlip(), \n",
        "                transforms.ToTensor() ,transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])])\n",
        "\n",
        "training_data =  datasets.Flowers102(root='data', split='train', download= True, transform= training_transfrom)\n",
        "\n",
        "training_loader = DataLoader(training_data, batch_size=batch_size, shuffle= True, num_workers=2)\n",
        "\n",
        "val_transform = transforms.Compose([transforms.Resize((width,height)),transforms.ToTensor(), \n",
        "                                    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])])\n",
        "val_data = datasets.Flowers102(root='data', split = 'val', download=True, transform = val_transform)\n",
        "\n",
        "val_loader = DataLoader(val_data, batch_size= batch_size, shuffle=True)\n",
        "\n",
        "test_transform = transforms.Compose([transforms.Resize((width,height)), transforms.ToTensor(), \n",
        "                                     transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])])\n",
        "\n",
        "test_data = datasets.Flowers102(root='data', split = 'test', download = True, transform = test_transform)\n",
        "test_loader = DataLoader(test_data, batch_size= batch_size, shuffle = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTOAn4loaNJ0",
        "outputId": "90f558eb-5b71-46c7-c709-2967e1390353"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 344862509/344862509 [00:11<00:00, 30718862.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/flowers-102/102flowers.tgz to data/flowers-102\n",
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to data/flowers-102/imagelabels.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 502/502 [00:00<00:00, 525465.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to data/flowers-102/setid.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14989/14989 [00:00<00:00, 13476617.93it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=96, kernel_size=(11,11), stride = (4,4), padding=(1,1))\n",
        "        self.bn1 = nn.BatchNorm2d(96)\n",
        "        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=(5,5), stride = (1,1), padding=(1,1))\n",
        "        self.bn2 = nn.BatchNorm2d(256)\n",
        "        self.conv3 = nn.Conv2d(in_channels=256, out_channels= 384, kernel_size= (3,3), stride=(1,1), padding=(1,1))\n",
        "        self.bn3 = nn.BatchNorm2d(384)\n",
        "        self.conv4 = nn.Conv2d(in_channels = 384, out_channels= 384, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "        self.bn4 = nn.BatchNorm2d(384)\n",
        "        self.conv5 = nn.Conv2d(in_channels=384, out_channels= 256, kernel_size=(3,3), padding=(1,1))\n",
        "        self.bn5 = nn.BatchNorm2d(256)\n",
        "        self.pool = nn.MaxPool2d(kernel_size= (3,3), stride= (2,2))\n",
        "        self.fc1 = nn.Linear(256*5*5, 4096)\n",
        "        self.bn6 = nn.BatchNorm1d(4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.bn7 = nn.BatchNorm1d(4096)\n",
        "        self.fc3 = nn.Linear(4096, 102)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = F.relu(self.bn5(self.conv5(x)))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 256 * 5 * 5)\n",
        "        x = F.relu(self.bn6(self.fc1(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.bn7(self.fc2(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "model = CNN().to(device)\n",
        "\n",
        "optimiser = optim.SGD(model.parameters(),lr=learning_rate, momentum=0.9)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# scheduler = optim.lr_scheduler.StepLR(optimiser, step_size= 20, gamma=0.75, verbose= True)\n",
        "\n",
        "# x = torch.randn(0, 3, 240, 240)\n",
        "# y = model(x)\n",
        "# print(y.shape)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt3ebw6VZtyh",
        "outputId": "e9c939b6-e596-4345-cac3-303f892a07ea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv1): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4), padding=(1, 1))\n",
            "  (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv5): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=6400, out_features=4096, bias=True)\n",
            "  (bn6): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "  (bn7): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc3): Linear(in_features=4096, out_features=102, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = next(iter(training_loader))\n",
        "\n",
        "image = image.to(device)\n",
        "\n",
        "x = F.relu(model.conv1(image))\n",
        "x = model.pool(x)\n",
        "# print(x.shape)\n",
        "x = F.relu(model.conv2(x))\n",
        "x = model.pool(x)\n",
        "# print(x.shape)\n",
        "x = F.relu(model.conv3(x))\n",
        "# x = model.pool(x)\n",
        "# print(x.shape)\n",
        "x = F.relu(model.conv4(x))\n",
        "# x = model.pool(x)\n",
        "x = F.relu(model.conv5(x))\n",
        "x = model.pool(x)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrN6s-nAZ5f7",
        "outputId": "e5a05c60-f6f2-4a1c-eb3e-3862cbed5dc0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 256, 5, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(Epoch_num):\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    best_accuracy = 38\n",
        "\n",
        "    \n",
        "    model.train()\n",
        "    for batch, (data,target) in enumerate(training_loader):\n",
        "        \n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        \n",
        "        optimiser.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = criterion(out, target)\n",
        "        loss.backward()\n",
        "        optimiser.step()\n",
        "        train_loss += loss.item() * data.size(0)\n",
        "        \n",
        "        \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for data, target in val_loader:\n",
        "        \n",
        "          data = data.to(device)\n",
        "          target = target.to(device)\n",
        "        \n",
        "          out = model(data)\n",
        "\n",
        "          _, predicted = torch.max(out.data, 1)\n",
        "\n",
        "          total += target.size(0)\n",
        "          correct += (predicted == target).sum().item()\n",
        "          loss = criterion(out, target)\n",
        "\n",
        "          valid_loss += loss.item() * data.size(0)\n",
        "          \n",
        "    accuracy = (correct / total) *100\n",
        "    \n",
        "    if(accuracy > best_accuracy):\n",
        "      best_accuracy = accuracy\n",
        "      torch.save(model, 'model_best')\n",
        "      \n",
        "    # if(learning_rate > 0.001):\n",
        "    #   scheduler.step()\n",
        "    train_loss = train_loss/len(training_loader.sampler)\n",
        "    valid_loss = valid_loss/len(val_loader.sampler)\n",
        "    # train_losses.append(train_loss)\n",
        "    # valid_lossess.append(valid_loss)\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tAccuracy: {:.6f}'.format(epoch, train_loss, valid_loss, accuracy))\n",
        "    \n",
        "\n",
        "def final_test(test_loader, model):\n",
        "  with torch.no_grad():\n",
        "    correct = 0 \n",
        "    total = 0\n",
        "    for data, target in test_loader:\n",
        "      data = data.to(device)\n",
        "      target = target.to(device)\n",
        "\n",
        "      out = model(data)\n",
        "\n",
        "      _, predicted = torch.max(out.data, 1)\n",
        "\n",
        "      total += target.size(0)\n",
        "\n",
        "      correct +=( predicted == target).sum().item()\n",
        "\n",
        "    accuracy = (correct / total) *100\n",
        "    print(\"Accuracy: {:.2f}\".format(accuracy))\n",
        "\n",
        "best_model = torch.load('model_best')\n",
        "final_test(test_loader, best_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXWZ4qmKaGwx",
        "outputId": "845a198e-01e3-420e-e834-e273b40c76d4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 \tTraining Loss: 4.722095 \tValidation Loss: 12.792345 \tAccuracy: 0.980392\n",
            "Epoch: 1 \tTraining Loss: 4.244541 \tValidation Loss: 4.969439 \tAccuracy: 7.352941\n",
            "Epoch: 2 \tTraining Loss: 3.971824 \tValidation Loss: 4.069124 \tAccuracy: 9.509804\n",
            "Epoch: 3 \tTraining Loss: 3.741353 \tValidation Loss: 4.586453 \tAccuracy: 10.000000\n",
            "Epoch: 4 \tTraining Loss: 3.677025 \tValidation Loss: 4.156301 \tAccuracy: 14.901961\n",
            "Epoch: 5 \tTraining Loss: 3.343192 \tValidation Loss: 4.048090 \tAccuracy: 16.470588\n",
            "Epoch: 6 \tTraining Loss: 3.282412 \tValidation Loss: 3.998925 \tAccuracy: 16.862745\n",
            "Epoch: 7 \tTraining Loss: 3.156085 \tValidation Loss: 3.991497 \tAccuracy: 14.705882\n",
            "Epoch: 8 \tTraining Loss: 3.028406 \tValidation Loss: 4.046847 \tAccuracy: 19.117647\n",
            "Epoch: 9 \tTraining Loss: 2.945892 \tValidation Loss: 4.022876 \tAccuracy: 20.882353\n",
            "Epoch: 10 \tTraining Loss: 2.807807 \tValidation Loss: 4.798572 \tAccuracy: 16.372549\n",
            "Epoch: 11 \tTraining Loss: 2.719064 \tValidation Loss: 3.959620 \tAccuracy: 22.647059\n",
            "Epoch: 12 \tTraining Loss: 2.598220 \tValidation Loss: 3.637840 \tAccuracy: 23.921569\n",
            "Epoch: 13 \tTraining Loss: 2.393006 \tValidation Loss: 3.824500 \tAccuracy: 23.137255\n",
            "Epoch: 14 \tTraining Loss: 2.419189 \tValidation Loss: 3.645753 \tAccuracy: 25.980392\n",
            "Epoch: 15 \tTraining Loss: 2.165374 \tValidation Loss: 3.909050 \tAccuracy: 24.607843\n",
            "Epoch: 16 \tTraining Loss: 2.017583 \tValidation Loss: 3.571012 \tAccuracy: 25.980392\n",
            "Epoch: 17 \tTraining Loss: 1.948880 \tValidation Loss: 3.572377 \tAccuracy: 29.215686\n",
            "Epoch: 18 \tTraining Loss: 1.764353 \tValidation Loss: 3.799787 \tAccuracy: 27.254902\n",
            "Epoch: 19 \tTraining Loss: 1.737423 \tValidation Loss: 4.059530 \tAccuracy: 28.921569\n",
            "Epoch: 20 \tTraining Loss: 1.642329 \tValidation Loss: 3.698209 \tAccuracy: 28.725490\n",
            "Epoch: 21 \tTraining Loss: 1.489228 \tValidation Loss: 3.820556 \tAccuracy: 29.705882\n",
            "Epoch: 22 \tTraining Loss: 1.415128 \tValidation Loss: 3.574126 \tAccuracy: 32.352941\n",
            "Epoch: 23 \tTraining Loss: 1.307329 \tValidation Loss: 3.719982 \tAccuracy: 31.862745\n",
            "Epoch: 24 \tTraining Loss: 1.195237 \tValidation Loss: 3.410794 \tAccuracy: 35.588235\n",
            "Epoch: 25 \tTraining Loss: 1.054034 \tValidation Loss: 3.593613 \tAccuracy: 35.294118\n",
            "Epoch: 26 \tTraining Loss: 1.000302 \tValidation Loss: 3.567464 \tAccuracy: 34.411765\n",
            "Epoch: 27 \tTraining Loss: 0.981044 \tValidation Loss: 3.699142 \tAccuracy: 32.352941\n",
            "Epoch: 28 \tTraining Loss: 0.919846 \tValidation Loss: 3.468777 \tAccuracy: 36.274510\n",
            "Epoch: 29 \tTraining Loss: 0.874337 \tValidation Loss: 3.595486 \tAccuracy: 34.901961\n",
            "Epoch: 30 \tTraining Loss: 0.808481 \tValidation Loss: 3.540357 \tAccuracy: 36.274510\n",
            "Epoch: 31 \tTraining Loss: 0.624100 \tValidation Loss: 3.404197 \tAccuracy: 36.666667\n",
            "Epoch: 32 \tTraining Loss: 0.615836 \tValidation Loss: 3.787405 \tAccuracy: 35.294118\n",
            "Epoch: 33 \tTraining Loss: 0.534713 \tValidation Loss: 3.547298 \tAccuracy: 37.647059\n",
            "Epoch: 34 \tTraining Loss: 0.558987 \tValidation Loss: 3.490912 \tAccuracy: 40.294118\n",
            "Epoch: 35 \tTraining Loss: 0.473305 \tValidation Loss: 3.382296 \tAccuracy: 39.313725\n",
            "Epoch: 36 \tTraining Loss: 0.442707 \tValidation Loss: 3.596243 \tAccuracy: 40.294118\n",
            "Epoch: 37 \tTraining Loss: 0.440435 \tValidation Loss: 3.379339 \tAccuracy: 38.921569\n",
            "Epoch: 38 \tTraining Loss: 0.393489 \tValidation Loss: 3.548363 \tAccuracy: 39.803922\n",
            "Epoch: 39 \tTraining Loss: 0.361074 \tValidation Loss: 3.495460 \tAccuracy: 41.470588\n",
            "Epoch: 40 \tTraining Loss: 0.379748 \tValidation Loss: 3.458340 \tAccuracy: 39.509804\n",
            "Epoch: 41 \tTraining Loss: 0.345308 \tValidation Loss: 3.456080 \tAccuracy: 42.156863\n",
            "Epoch: 42 \tTraining Loss: 0.364659 \tValidation Loss: 3.515682 \tAccuracy: 41.470588\n",
            "Epoch: 43 \tTraining Loss: 0.302056 \tValidation Loss: 3.687609 \tAccuracy: 41.176471\n",
            "Epoch: 44 \tTraining Loss: 0.309745 \tValidation Loss: 3.621088 \tAccuracy: 38.823529\n",
            "Epoch: 45 \tTraining Loss: 0.311276 \tValidation Loss: 3.463043 \tAccuracy: 40.980392\n",
            "Epoch: 46 \tTraining Loss: 0.264204 \tValidation Loss: 3.570436 \tAccuracy: 40.980392\n",
            "Epoch: 47 \tTraining Loss: 0.257840 \tValidation Loss: 3.313765 \tAccuracy: 42.745098\n",
            "Epoch: 48 \tTraining Loss: 0.284793 \tValidation Loss: 3.561464 \tAccuracy: 41.176471\n",
            "Epoch: 49 \tTraining Loss: 0.307532 \tValidation Loss: 3.738027 \tAccuracy: 40.882353\n",
            "Epoch: 50 \tTraining Loss: 0.240676 \tValidation Loss: 3.603364 \tAccuracy: 42.254902\n",
            "Epoch: 51 \tTraining Loss: 0.179976 \tValidation Loss: 3.604258 \tAccuracy: 41.176471\n",
            "Epoch: 52 \tTraining Loss: 0.223107 \tValidation Loss: 3.468680 \tAccuracy: 43.039216\n",
            "Epoch: 53 \tTraining Loss: 0.210317 \tValidation Loss: 3.748585 \tAccuracy: 41.372549\n",
            "Epoch: 54 \tTraining Loss: 0.228979 \tValidation Loss: 3.549535 \tAccuracy: 41.862745\n",
            "Epoch: 55 \tTraining Loss: 0.164951 \tValidation Loss: 3.475094 \tAccuracy: 45.588235\n",
            "Epoch: 56 \tTraining Loss: 0.124640 \tValidation Loss: 3.345371 \tAccuracy: 45.686275\n",
            "Epoch: 57 \tTraining Loss: 0.131751 \tValidation Loss: 3.432094 \tAccuracy: 45.196078\n",
            "Epoch: 58 \tTraining Loss: 0.163774 \tValidation Loss: 3.714592 \tAccuracy: 41.176471\n",
            "Epoch: 59 \tTraining Loss: 0.127667 \tValidation Loss: 3.429267 \tAccuracy: 44.313725\n",
            "Epoch: 60 \tTraining Loss: 0.108256 \tValidation Loss: 3.299477 \tAccuracy: 46.862745\n",
            "Epoch: 61 \tTraining Loss: 0.100868 \tValidation Loss: 3.392676 \tAccuracy: 45.882353\n",
            "Epoch: 62 \tTraining Loss: 0.109810 \tValidation Loss: 3.505553 \tAccuracy: 44.215686\n",
            "Epoch: 63 \tTraining Loss: 0.123287 \tValidation Loss: 3.461592 \tAccuracy: 44.019608\n",
            "Epoch: 64 \tTraining Loss: 0.136177 \tValidation Loss: 3.476279 \tAccuracy: 43.921569\n",
            "Epoch: 65 \tTraining Loss: 0.121078 \tValidation Loss: 3.615443 \tAccuracy: 44.019608\n",
            "Epoch: 66 \tTraining Loss: 0.079558 \tValidation Loss: 3.587315 \tAccuracy: 45.098039\n",
            "Epoch: 67 \tTraining Loss: 0.108430 \tValidation Loss: 3.378141 \tAccuracy: 47.156863\n",
            "Epoch: 68 \tTraining Loss: 0.095621 \tValidation Loss: 3.413887 \tAccuracy: 46.960784\n",
            "Epoch: 69 \tTraining Loss: 0.101705 \tValidation Loss: 3.529517 \tAccuracy: 45.000000\n",
            "Epoch: 70 \tTraining Loss: 0.101448 \tValidation Loss: 3.573607 \tAccuracy: 44.117647\n",
            "Epoch: 71 \tTraining Loss: 0.086681 \tValidation Loss: 3.314434 \tAccuracy: 45.588235\n",
            "Epoch: 72 \tTraining Loss: 0.089704 \tValidation Loss: 3.309673 \tAccuracy: 47.450980\n",
            "Epoch: 73 \tTraining Loss: 0.065171 \tValidation Loss: 3.376708 \tAccuracy: 45.784314\n",
            "Epoch: 74 \tTraining Loss: 0.072438 \tValidation Loss: 3.452258 \tAccuracy: 45.686275\n",
            "Epoch: 75 \tTraining Loss: 0.065670 \tValidation Loss: 3.237088 \tAccuracy: 49.313725\n",
            "Epoch: 76 \tTraining Loss: 0.063980 \tValidation Loss: 3.412438 \tAccuracy: 48.431373\n",
            "Epoch: 77 \tTraining Loss: 0.064370 \tValidation Loss: 3.343137 \tAccuracy: 48.039216\n",
            "Epoch: 78 \tTraining Loss: 0.044519 \tValidation Loss: 3.277378 \tAccuracy: 47.941176\n",
            "Epoch: 79 \tTraining Loss: 0.058363 \tValidation Loss: 3.414276 \tAccuracy: 47.647059\n",
            "Epoch: 80 \tTraining Loss: 0.045936 \tValidation Loss: 3.439521 \tAccuracy: 47.647059\n",
            "Epoch: 81 \tTraining Loss: 0.050091 \tValidation Loss: 3.278457 \tAccuracy: 47.941176\n",
            "Epoch: 82 \tTraining Loss: 0.046793 \tValidation Loss: 3.229943 \tAccuracy: 49.117647\n",
            "Epoch: 83 \tTraining Loss: 0.051950 \tValidation Loss: 3.462418 \tAccuracy: 46.372549\n",
            "Epoch: 84 \tTraining Loss: 0.059688 \tValidation Loss: 3.425058 \tAccuracy: 46.274510\n",
            "Epoch: 85 \tTraining Loss: 0.058180 \tValidation Loss: 3.374563 \tAccuracy: 46.470588\n",
            "Epoch: 86 \tTraining Loss: 0.041873 \tValidation Loss: 3.414703 \tAccuracy: 46.862745\n",
            "Epoch: 87 \tTraining Loss: 0.045426 \tValidation Loss: 3.419828 \tAccuracy: 47.647059\n",
            "Epoch: 88 \tTraining Loss: 0.039470 \tValidation Loss: 3.380973 \tAccuracy: 47.647059\n",
            "Epoch: 89 \tTraining Loss: 0.030707 \tValidation Loss: 3.285442 \tAccuracy: 49.803922\n",
            "Epoch: 90 \tTraining Loss: 0.030984 \tValidation Loss: 3.501661 \tAccuracy: 47.254902\n",
            "Epoch: 91 \tTraining Loss: 0.036630 \tValidation Loss: 3.430732 \tAccuracy: 48.627451\n",
            "Epoch: 92 \tTraining Loss: 0.042706 \tValidation Loss: 3.445251 \tAccuracy: 47.549020\n",
            "Epoch: 93 \tTraining Loss: 0.034972 \tValidation Loss: 3.315842 \tAccuracy: 47.941176\n",
            "Epoch: 94 \tTraining Loss: 0.035877 \tValidation Loss: 3.398148 \tAccuracy: 46.862745\n",
            "Epoch: 95 \tTraining Loss: 0.055373 \tValidation Loss: 3.487368 \tAccuracy: 47.156863\n",
            "Epoch: 96 \tTraining Loss: 0.039797 \tValidation Loss: 3.329590 \tAccuracy: 48.137255\n",
            "Epoch: 97 \tTraining Loss: 0.038641 \tValidation Loss: 3.559299 \tAccuracy: 44.901961\n",
            "Epoch: 98 \tTraining Loss: 0.060626 \tValidation Loss: 3.583932 \tAccuracy: 45.294118\n",
            "Epoch: 99 \tTraining Loss: 0.047339 \tValidation Loss: 3.574040 \tAccuracy: 45.588235\n",
            "Accuracy: 41.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w2t23ek7anQ9"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}